{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl-SyroWBx8S"
   },
   "source": [
    "\n",
    "```\n",
    "This assignment involves implementing a neural network with a single linear layer followed by softmax, for a 3-class classification problem. You are allowed to use any functionality from scipy and numpy, but no other library should be used in the implementation. You can use matplotlib or other plotting library for the plots. \n",
    "\n",
    "Given is the following dataset (same as previous PSS), where each row is a sample represented by a 4-pixel image and the measured output is the last column.\n",
    "\n",
    "$D_{train}$ = [[255, 128, 128, 0, 0], [55, 128, 128, 128, 1], [192, 128, 128, 0, 0],\n",
    "\n",
    "[100, 128, 128, 100, 1], [30, 64, 128, 30, 2], [20, 64, 128, 0, 2]]\n",
    "\n",
    "\n",
    "Consider a neural network (NN) composed of 3 linear activations (a single fully-connected layer), followed by softmax, parameterized by weights W with shape 4x3 and biases B with shape 1x3, initialized with the values 0.\n",
    "\n",
    "We will use cross-entropy loss and gradient descent. Refer to the lectures notes or the current Pen+Paper assignment for the parameter update equations.\n",
    "\n",
    "Submit using mycourses dropbox. Save the file in ipynb format.\n",
    "Your submission will be shared with all your classmates.\n",
    "\n",
    "You are allowed to research code online or use LLM code generators.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialization\n",
    "\n",
    "Let's first create some numpy arrays which correspond to weight and bias matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "W = np.zeros((4, 3))\n",
    "b = np.zeros((1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature data & ground truth arrays\n",
    "\n",
    "Save the feature data and the ground truth in numpy arrays and show their shapes.\n",
    "\n",
    "You need to create the feature array X incorporating the bias. Y will be your one-hot encoded ground-truth (target) numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTM556nW9idu"
   },
   "outputs": [],
   "source": [
    "MAX_VALUE = 255\n",
    "samples = [[255, 128, 128, 0, 0], [55, 128, 128, 128, 1], [192, 128, 128, 0, 0],\n",
    "[100, 128, 128, 100, 1], [30, 64, 128, 30, 2], [20, 64, 128, 0, 2]]\n",
    "\n",
    "# divide by max value and get normalized values\n",
    "images = [[s / MAX_VALUE for s in sample[:-1]] for sample in samples]\n",
    "\n",
    "X = []\n",
    "for image in images:\n",
    "    lst = [1]\n",
    "    lst.extend(image)\n",
    "    X.append(lst)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "Y_labels = np.array([sample[-1] for sample in samples])\n",
    "num_classes = np.max(Y_labels) + 1 # 3\n",
    "\n",
    "# one hot encoding\n",
    "Y = np.eye(num_classes)[Y_labels]\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of Y: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot the images in grayscale\n",
    "(2x2 pixels each image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(8, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (image, label) in enumerate(zip(images, Y_labels)):\n",
    "    reshaped_img = np.array(image).reshape(2, -1)\n",
    "    axes[i].imshow(reshaped_img, cmap='gray', vmin=0, vmax=1, aspect='auto')\n",
    "\n",
    "    axes[i].set_title(f\"Sample {i + 1} (Class {label})\")\n",
    "\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Forward pass\n",
    "Using loops, implement the neural network forward pass.\n",
    "\n",
    "We will want to calculate the output logits `Z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image arrays as numpy arrays\n",
    "images = [np.array(image) for image in images]\n",
    "\n",
    "def forward_pass(images):\n",
    "    # output logits - 3 total layers\n",
    "    Z = []\n",
    "    total_classes = W.shape[1]\n",
    "\n",
    "    for image in images:\n",
    "        Z_sample = []\n",
    "\n",
    "        for j in range(total_classes):\n",
    "            x_dot_w_j = sum([W[i, j] * image[i] for i in range(len(image))])\n",
    "            # x_dot_w_j = W[:, j].T @ image\n",
    "\n",
    "            l_j = b[:, j] + x_dot_w_j\n",
    "\n",
    "            Z_sample.append(l_j[0])\n",
    "        Z.append(Z_sample)\n",
    "\n",
    "    return Z\n",
    "\n",
    "test_forward_pass = forward_pass(images)\n",
    "test_forward_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Backward pass\n",
    "Using loops, implement the neural network backward pass.\n",
    "\n",
    "We can calculate the error here and use the given equations to implement the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(images, mat_logits, Y_labels, W, b, lr=0.1):\n",
    "    N_samples = len(images)\n",
    "    total_features = W.shape[0]\n",
    "    total_classes = W.shape[1]\n",
    "\n",
    "    # calculate weight update\n",
    "    delta_w_loops = np.zeros((total_features, total_classes))\n",
    "    delta_b_loops = np.zeros((1, total_classes))\n",
    "    \n",
    "    for s in range(N_samples):\n",
    "        image = images[s]\n",
    "        logits = mat_logits[s]\n",
    "        y_label = Y_labels[s]\n",
    "\n",
    "        # apply softmax\n",
    "        p_j = sp.special.softmax(logits)\n",
    "\n",
    "        # make one-hot vector, find error\n",
    "        y = np.eye(total_classes)[y_label]\n",
    "        err = p_j - y\n",
    "\n",
    "        for i in range(total_features):\n",
    "            for j in range(total_classes):\n",
    "                delta_w_loops[i, j] += image[i] * err[j]\n",
    "\n",
    "        # image = image.reshape((1, -1))\n",
    "        # err = err.reshape((1, -1))\n",
    "        # delta_w = lr * (image.T @ err)\n",
    "\n",
    "        # calculate bias update\n",
    "        delta_b_loops[0, :] += err[:]\n",
    "\n",
    "    delta_w_avg = lr * (delta_w_loops / N_samples)\n",
    "    delta_b_avg = lr * (delta_b_loops / N_samples)\n",
    "\n",
    "    # update weight and bias\n",
    "    W_updated = W - delta_w_avg\n",
    "    b_updated = b - delta_b_avg\n",
    "        \n",
    "    return W_updated, b_updated\n",
    "\n",
    "test_backward_pass = backward_pass(images, test_forward_pass, Y_labels, W, b)\n",
    "test_backward_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Forward pass (vector form)\n",
    "Using the vector-form (using no loops in the code), implement the neural network forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_vector(X, W, b):\n",
    "    # augment W\n",
    "    W_augmented = np.vstack([b, W])\n",
    "\n",
    "    # output logits - 3 total layers\n",
    "    Z = X @ W_augmented\n",
    "\n",
    "    return Z\n",
    "\n",
    "test_forward_pass = forward_pass_vector(X, W, b)\n",
    "test_forward_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Backward pass (vector-form) \n",
    "Using the vector-form (using no loops in the code), implement the neural network backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass_vector(images, mat_logits, Y_labels, W, b, lr=0.1):\n",
    "    # get params\n",
    "    N_samples = len(images)\n",
    "    total_classes = W.shape[1]\n",
    "\n",
    "    # apply softmax row-wise\n",
    "    S = sp.special.softmax(mat_logits, axis=1)\n",
    "\n",
    "    # get one-hot encoded matrix\n",
    "    Y = np.eye(total_classes)[Y_labels]\n",
    "\n",
    "    # get error\n",
    "    E = S - Y\n",
    "\n",
    "    # weight and bias updates (averaged)\n",
    "    delta_W = lr * ((np.array(images).T @ E) / N_samples)\n",
    "    delta_b = lr * (np.mean(E, axis=0, keepdims=True))\n",
    "\n",
    "    W_updated = W - delta_W\n",
    "    b_updated = b - delta_b\n",
    "\n",
    "    return W_updated, b_updated\n",
    "\n",
    "test_backward_pass = backward_pass_vector(images, test_forward_pass, Y_labels, W, b)\n",
    "test_backward_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 10-epoch training with error\n",
    "Train this model for 10 epochs (1 averaged update for 1 full pass on the dataset), using the learning rate of 0.3. Repeat for learning # rate of 0.5. Write down the new accuracy after each update.\n",
    "\n",
    "Now print the error for each update (same training process, don't resume/repeat the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.3, 0.5]\n",
    "EPOCHS = 10\n",
    "\n",
    "def run_epoch_vector(images, Y_labels, X, W, b, lr):\n",
    "    logits = forward_pass_vector(X, W, b)\n",
    "    updates = backward_pass_vector(images, logits, Y_labels, W, b, lr)\n",
    "\n",
    "    return updates\n",
    "    \n",
    "results = {}\n",
    "\n",
    "def run_training_vector(X, W, b, Y_labels, epochs=10, lr=0.1):\n",
    "    W_training = W[:]\n",
    "    b_training = b[:]\n",
    "\n",
    "    init_loss, init_acc = epoch_stats(X, W, b, Y_labels)\n",
    "\n",
    "    losses = [init_loss]\n",
    "    accuracies = [init_acc]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Running epoch {epoch + 1} with learning rate {lr}...\", end=\"\")\n",
    "        W_updated, b_updated = run_epoch_vector(images, Y_labels, X, W_training, b_training, lr)\n",
    "        W_training = W_updated\n",
    "        b_training = b_updated\n",
    "\n",
    "        loss, acc = epoch_stats(X, W_training, b_training, Y_labels)\n",
    "        losses.append(loss)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"Loss: {loss}, Accuracy: {acc:.2%}\\n\")\n",
    "\n",
    "    print(f\"Final stats for training {epoch + 1} epochs with learning rate {lr}:\\nLoss: {loss:.4f}\\nAccuracy: {acc:.2%}\")\n",
    "\n",
    "    return losses, accuracies\n",
    "\n",
    "def epoch_stats(X, W, b, Y_labels):\n",
    "    logits = forward_pass_vector(X, W, b)\n",
    "\n",
    "    # apply softmax row-wise\n",
    "    S = sp.special.softmax(logits, axis=1)\n",
    "\n",
    "    # get one-hot encoded matrix\n",
    "    Y = np.eye(W.shape[1])[Y_labels]\n",
    "\n",
    "    # loss calculation\n",
    "    epsilon = 1e-12\n",
    "    S_clipped = np.clip(S, epsilon, 1. - epsilon)\n",
    "\n",
    "    L_sample = Y * np.log(S_clipped)\n",
    "    cross_entropy = -np.mean(np.sum(L_sample, axis=1))\n",
    "\n",
    "    # accuracy calculation\n",
    "    predictions = np.argmax(S, axis=1)\n",
    "    correct = (predictions == Y_labels)\n",
    "\n",
    "    print(f\" Predictions: {predictions}, Actual: {Y_labels}\")\n",
    "\n",
    "    accuracy = np.mean(correct)\n",
    "\n",
    "    return cross_entropy, accuracy\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Running trial with learning rate {lr}:\\n-=-=-=-=-=-=-=-=-\\n\")\n",
    "    ls, accs = run_training_vector(X, W, b, Y_labels, epochs=EPOCHS, lr=lr)\n",
    "\n",
    "    results[lr] = {'loss_history': ls, 'acc_history': accs}\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plotted error by epoch\n",
    "Plot the error (loss output) over the 10 epochs, for both learning rates. You need to present 2 error plots (one for each learning rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Plotted accuracy by epoch\n",
    "\n",
    "Plot the accuracy over the 10 epochs, for both learning rates. You need to present 2 accuracy plots (one for each learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(training_results, epochs):\n",
    "    epochs_range = range(epochs + 1)\n",
    "    \n",
    "    # plot loss plots\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Cross-Entropy Loss vs. Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    \n",
    "    for lr, data in training_results.items():\n",
    "        plt.plot(epochs_range, data['loss_history'], label=f'LR = {lr}')\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot accuracy plots\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Accuracy vs. Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    \n",
    "    for lr, data in training_results.items():\n",
    "        plt.plot(epochs_range, data['acc_history'], label=f'LR = {lr}')\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_training_results(results, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7uUggBOdLTeMV3WSnfNR9",
   "provenance": [
    {
     "file_id": "1JFEun35RpBvj5m84jMN9yLkZY6Y8jeXr",
     "timestamp": 1738941712714
    }
   ]
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
